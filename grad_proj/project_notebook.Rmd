---
title: "JOUR772 Grad Assignment"
author: "Aidan Hughes"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidycensus)
library(janitor)
```


# Analysis 1:

Use the "Maryland International Migration: 2001-2021" data set in combination with 2020 election results to see whether regions experiencing higher rates of migration are positively correlated with a vote swing towards Donald Trump in 2020

## Sources:

- Migration data: https://opendata.maryland.gov/Demographic/Maryland-International-Migration-2001-2021/hq27-cfrc

- 2020 Election results: https://docs.google.com/spreadsheets/d/1oSzr7O14vzRxeethgAnugADhgHhZG4xX1DOh1ElmCNc/edit?usp=sharing
  (I manually copied and pasted this data from https://elections.maryland.gov/elections/2020/results/general/gen_detail_results_p2020_4_BOT001-.html)

- Population data: 2016 and 2020 ACS data

```{r}
# Load the Maryland Migration data


migration_df <- read_csv("data/Maryland_International_Migration__2001-2021.csv")

migration_df_transformed <- migration_df %>%
  select(-`Date created`) %>%
  pivot_longer(cols = !Year,
               names_to = "county",
               values_to = "migration")
```

```{r}
#Make a df showing total migration from 2013-2016 per county

migration_13_16 <- migration_df_transformed %>%
  filter(Year >= 2013 & Year <= 2016) %>%
  group_by(county) %>%
  summarize(total_migration = sum(migration)) %>%
  mutate(county = str_replace(county, " County", ""))

#ChatGPT helped with this line
migration_13_16$county[migration_13_16$county == "MARYLAND"] <- "State Level"

migration_13_16
```

```{r}
#Make a df showing total migration from 2017-2020 per county

migration_17_20 <- migration_df_transformed %>%
  filter(Year >= 2017 & Year <= 2020) %>%
  group_by(county) %>%
  summarize(total_migration = sum(migration)) %>%
  mutate(county = str_replace(county, " County", ""))

#ChatGPT helped with this line
migration_17_20$county[migration_17_20$county == "MARYLAND"] <- "State Level"

migration_17_20
```


```{r}
# Load 2020 election data

md_2020_county_election_results <- read_delim("data/md_2020_county_election_results.csv") %>%
  clean_names() %>%
  #chatGPT helped me with the next four lines
  rowwise() %>%
  mutate(total_county_votes = sum(c_across(-1), na.rm = TRUE)) %>%
  select(jurisdiction, donald_j_trump_and_michael_pence_republican, total_county_votes)

# Create a new row with "State Level" in the "jurisdiction" column
# and the sum of the second column
new_row <- data.frame(jurisdiction = "State Level", donald_j_trump_and_michael_pence_republican = sum(md_2020_county_election_results$donald_j_trump_and_michael_pence_republican), total_county_votes = sum(md_2020_county_election_results$total_county_votes))

# Bind the new row to the original dataframe
md_2020_county_election_results <- rbind(md_2020_county_election_results, new_row)

md_2020_county_election_results

```


```{r}
# join the migration data

md_2020_election_and_migration <- migration_17_20 %>%
  left_join(md_2020_county_election_results, join_by("county" == "jurisdiction"))


md_2020_election_and_migration
```


```{r}
# load ACS data for 2020 (variable: B01003_001)

population_2020 <- get_acs(geography = "county",
              variables = "B01003_001",
              state = "MD",
              year = 2020) %>%
  mutate("NAME" = gsub(", Maryland", "", NAME)) %>%
      arrange(estimate) %>%
  select(GEOID, NAME, estimate) %>%
  mutate()

new_row <- population_2020 %>%
  summarize(GEOID = "24", NAME = "State Level", estimate = sum(estimate))

population_2020 <- bind_rows(population_2020, new_row) %>%
  mutate(NAME = str_replace(NAME, " County", "")) %>%
  mutate(NAME = str_replace(NAME, "city", "City"))

population_2020

```

```{r}
# join with the migration and election data

full_2020_df <- md_2020_election_and_migration %>%
  left_join(population_2020, join_by("county" == "NAME"))

full_2020_df

```

```{r}
# calculate Trump's vote share %

full_2020_df <- full_2020_df %>%
  mutate(trump_vote_share = donald_j_trump_and_michael_pence_republican / total_county_votes * 100) %>%
  mutate(migration_per_capita = total_migration / estimate * 10000)

full_2020_df %>%
  select(trump_vote_share, migration_per_capita)
```

Plot the data to see if any Pearson assumptions are violated:

```{r}
ggplot(full_2020_df, aes(x = trump_vote_share, y = migration_per_capita)) +
  geom_point()
```


There's heteroscedasticity. My data also isn't normally distributed:

```{r}
# Create a histogram
ggplot(full_2020_df, aes(x = migration_per_capita)) +
  geom_histogram(binwidth = 20, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Migration Per Capita",
       x = "Migration Per Capita",
       y = "Frequency")

# Summary statistics
summary(full_2020_df$migration_per_capita)
```

Let's use Kendall's Tau to test correlation since it doesn't rely on an assumption of normally distributed data or homoscedasticity, and is also better with small sample sizes than Spearman

```{r}

# Kendall's Tau correlation test
cor_test_result_kendall <- cor.test(full_2020_df$migration_per_capita, full_2020_df$trump_vote_share, method = "kendall")

# Print the result
print(cor_test_result_kendall)

```

```{r}
# Scatterplot with smooth line
ggplot(full_2020_df, aes(x = trump_vote_share, y = migration_per_capita)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +  # Add a smooth line
  labs(title = paste("Kendall's Tau =", round(cor_test_result_kendall$estimate, 3), "\n p-value =", cor_test_result_kendall$p.value))
```

There's a moderate negative correlation between a county's per capita migration numbers and Trump's vote share in that county. There's also a strong P value. In other words, there's a halfway decent chance that a county experiencing higher levels of immigration is LESS likely to vote for Trump (this is only correlative,  can't determine causation here).
